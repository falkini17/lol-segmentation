{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp\n",
    "Poza tym notebookiem, który zawiera wszystkie operacje na danych jakie wykonałem w tej analizie, załączam również poglądowo notebook z algorytmem budującym analizowany zbiór danych (<i>[praca_magisterska] data_preparation.ipynb</i>). Kompilacja go wymaga podania klucza do API od Riot (producent LoL'a) - na Pana prośbę mogę go wygenerować i podesłać, jeśli chciałby Pan przejrzeć jak wyciągnąłem dane. Klucz autentykacyjny traci ważność po 24 godzinach, z tego względu obecnie kod się nie skompiluje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option(\"display.max_columns\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane = pd.read_csv('data_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Czyszczenie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierwotny zbiór danych, który wygenerowałem zawierał ponad 96 tysięcy obserwacji i 43 zmienne. Poniżej widać 5 poglądowych rekordów. Każda obserwacja to statystyki 1 gracza z 1 meczu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dane.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pierwszej kolejności chciałem ustalić, która z potencjalnych zmiennych, <b>role, individualPosition lub teamPosition</b>, będzie lepszą zmienną do jednoznacznego określenia roli jaką dany gracz odgrywał w meczu. Im bardziej zbalansowany będzie podział między rolami, tym lepsza jest to zmienna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane[['role','gameId']].groupby(['role']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane[['individualPosition','gameId']].groupby(['individualPosition']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane[['teamPosition','gameId']].groupby(['teamPosition']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab([dane['role'],dane['teamPosition']],dane['individualPosition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
    "ari_dataset = dane[['role','individualPosition','teamPosition']].dropna(0)\n",
    "ari_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_ip = adjusted_mutual_info_score(ari_dataset['role'],ari_dataset['individualPosition'])\n",
    "role_tp = adjusted_mutual_info_score(ari_dataset['role'],ari_dataset['teamPosition'])\n",
    "tp_ip = adjusted_mutual_info_score(ari_dataset['teamPosition'],ari_dataset['individualPosition'])\n",
    "print('Adjusted Mutual Information:')\n",
    "print('role_ip: '+str(role_ip))\n",
    "print('role_tp: '+str(role_tp))\n",
    "print('tp_ip: '+str(tp_ip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role_ip = adjusted_rand_score(ari_dataset['role'],ari_dataset['individualPosition'])\n",
    "role_tp = adjusted_rand_score(ari_dataset['role'],ari_dataset['teamPosition'])\n",
    "tp_ip = adjusted_rand_score(ari_dataset['teamPosition'],ari_dataset['individualPosition'])\n",
    "print('Adjusted Rand Index:')\n",
    "print('role_ip: '+str(role_ip))\n",
    "print('role_tp: '+str(role_tp))\n",
    "print('tp_ip: '+str(tp_ip))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po obliczeniu ARI (Adjusted Rand Index) oraz AMI (Adjusted Mutual Information) dla 3 kombinacji zmiennych widać, że najwyższe wartości obserwujemy dla zmiennej teamPosition - oznacza to, że jest ona najbardziej spójna z obiema pozostałymi zmiennymi, czyli jest syntezą informacji ze wszystkich 3. Dodatkowo jest bardzo zbalansowana - dlatego wybieram ją jako ground truth do późniejszej klasteryzacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na etapie tworzenia zbioru zorientowałem się, że mecze rozgrywane w różnych okresach funkcjonowania gry (a co za tym idzie różnymi wersjami API) były opisywany w inny sposób pod względem liczenia czasu rozgrywki. Zamiast czasu rozgrywki wyrażonego w sekundach posługiwano się milisekundami. Oznacza to, że dla sporej części obserwacji mam źle obliczone wartości statystyk w odniesieniu do czasu rozgrywki np. killsPerMinute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane['gameDurationMin'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane['gameDurationMin'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poprawne_czasy = dane[dane['gameDurationMin']>=5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane['gameDurationMin'][dane['gameDurationMin']<5].hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aby naprawić statystyki rozgrywki trzeba dla tych meczy, które mają krótki czas przemnożyć gameDurationMin razy 1000, a statystyki per Minute podzielić na 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_poprawy = dane[dane['gameDurationMin']<3].reset_index(drop=True)\n",
    "do_poprawy['longestTimeSpentLiving'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W zbiorze danych do poprawy dla niektorych rekordow (ponizej 1) trzeba zmienną longestTimeSpentLiving przemnożyć przez 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_poprawy['gameDurationMin'] = do_poprawy['gameDurationMin']*1000\n",
    "do_poprawy['killsPerMinute'] = do_poprawy['killsPerMinute']/1000\n",
    "do_poprawy['deathsPerMinute'] = do_poprawy['deathsPerMinute']/1000\n",
    "do_poprawy['assistsPerMinute'] = do_poprawy['assistsPerMinute']/1000\n",
    "do_poprawy['damageDealtPerMinute'] = do_poprawy['damageDealtPerMinute']/1000\n",
    "do_poprawy['damageDealtToChampionsPerMinute'] = do_poprawy['damageDealtToChampionsPerMinute']/1000\n",
    "do_poprawy['damageTakenPerMinute'] = do_poprawy['damageTakenPerMinute']/1000\n",
    "do_poprawy['damageSelfMitigatedPerMinute'] = do_poprawy['damageSelfMitigatedPerMinute']/1000\n",
    "do_poprawy['magicDamageDealtPerMinute'] = do_poprawy['magicDamageDealtPerMinute']/1000\n",
    "do_poprawy['physicalDamageDealtPerMinute'] = do_poprawy['physicalDamageDealtPerMinute']/1000\n",
    "do_poprawy['goldEarnedPerMinute'] = do_poprawy['goldEarnedPerMinute']/1000\n",
    "do_poprawy['goldSpentPerMinute'] = do_poprawy['goldSpentPerMinute']/1000\n",
    "do_poprawy['minionsKilledPerMinute'] = do_poprawy['minionsKilledPerMinute']/1000\n",
    "do_poprawy['wardsPlacedPerMinute'] = do_poprawy['wardsPlacedPerMinute']/1000\n",
    "do_poprawy['wardsKilledPerMinute'] = do_poprawy['wardsKilledPerMinute']/1000\n",
    "do_poprawy['inhibitorKillsPerMinute'] = do_poprawy['inhibitorKillsPerMinute']/1000\n",
    "do_poprawy['timeCrowdControlDealtPerMinute'] = do_poprawy['timeCrowdControlDealtPerMinute']/1000\n",
    "do_poprawy['experiencePerMinute'] = do_poprawy['experiencePerMinute']/1000\n",
    "do_poprawy['damageDealtToTurretsPerMinute'] = do_poprawy['damageDealtToTurretsPerMinute']/1000\n",
    "do_poprawy['ultimateCastsPerMinute'] = do_poprawy['ultimateCastsPerMinute']/1000\n",
    "do_poprawy['totalHealPerMinute'] = do_poprawy['totalHealPerMinute']/1000\n",
    "do_poprawy['turretKillsPerMinute'] = do_poprawy['turretKillsPerMinute']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poprawione_do_concat = do_poprawy[do_poprawy['longestTimeSpentLiving']>=0.1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poprawione_do_concat['longestTimeSpentLiving'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reszta = do_poprawy[do_poprawy['longestTimeSpentLiving']<0.1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reszta['longestTimeSpentLiving'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reszta['longestTimeSpentLiving'] = reszta['longestTimeSpentLiving']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reszta['longestTimeSpentLiving'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reszta_do_odratowania = reszta[reszta['longestTimeSpentLiving']>=10].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane = pd.concat([poprawne_czasy,poprawione_do_concat,reszta_do_odratowania]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane['gameDurationMin'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane['longestTimeSpentLiving'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz dane o czasie gry i najdluzszym czasie bez życia gracza mają sens. W następnych krokach odfiltrowuję za krótkie mecze (poniżej 15 minut - dopiero wtedy mecz może się w normalnych warunkach zakończyć wygraną którejś ze stron poprzez poddanie tej drugiej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane = dane[dane['gameDurationMin']>=15].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane['damageDealtPerMinute'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane[dane['damageDealtPerMinute']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane = dane[dane['damageDealtPerMinute']>0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usuwam zmienne, które posiadają niezrozumiałe dane: damageRatio - nieskończoność gdy gracz nie otrzymal zadnych obrazen oraz timeCrowdControlDealtPerMinute - mam wątpliwości czy te dane są dobrze policzone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns = dane.loc[:, ~dane.columns.isin(['damageRatio', 'timeCrowdControlDealtPerMinute'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatnim etapem jest usunięcie obserwacji z brakującymi danymi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns.isnull().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns[dane_filtered_columns.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns.columns[dane_filtered_columns.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kolejnym powodem, żeby usunąć te obserwacje jest fakt, że nie mają one bardzo istotnej zmiennej - teamPosition, którą wybrałem jako identyfikator roli gracza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns = dane_filtered_columns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns.groupby(['teamPosition']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns = dane_filtered_columns.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dane_filtered_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostateczny zbiór, z którym przechodzę do etapu PCA ma 93.5 tysiąca obserwacji i 41 zmiennych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redukcja wielowymiarowości - PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W związku z tak dużą liczbą wymiarów i zależnościami między nimi mam hipotezę, że w zbiorze zachodzi współliniowość i konieczna będzie redukcja wielowymiarowości, którą przeprowadzę metodą PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 7,7 \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "from heatmap import heatmap, corrplot\n",
    "sns.set(color_codes=True, font_scale=1.2)\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dane_filtered_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "corrplot(data.corr(), size_scale=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czyli potwierdzona hipoteza - mamy zjawisko współliniowości, przykłady:\n",
    "<br> <b>percentMagic - percentPhysical</b> silna odwrotna korelacja (oczywiste, bo dopelnieniem jednego jest drugie)\n",
    "<br> <b>playerRank - experiencePerMinute</b> silna odwrotna korelacja (sam tak stworzylem zmienna, wiec tez bez zaskoczen)\n",
    "<br> <b>champLevel - gameDurationMin</b> silna korelacja (ciekawe, im wyzszy poziom graczy tym mecze sa bardziej zaciete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przed nastepnymi krokami musze rozdzielic dane na zmienne liczbowe, ktore bede wykorzystywac w PCA oraz w klasteryzacji i na zmienne \"na potem\". Zmienne liczbowe muszę wyskalować przed PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = data.loc[:, ~data.columns.isin(['gameId', 'teamId','lane','role','playerRank','individualPosition','teamPosition','win','gameDurationMin','gameEndedInSurrender','championName'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_stats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(df_stats)\n",
    "data_std = sc.transform(df_stats)\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_pca = pca.fit_transform(data_std)\n",
    "\n",
    "exp_var_pca = pca.explained_variance_ratio_\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,8)\n",
    "plt.bar(range(0+1,len(exp_var_pca)+1), exp_var_pca, alpha=0.5, align='center', label='Wyjaśniona wariancja')\n",
    "plt.step(range(0+1,len(cum_sum_eigenvalues)+1), cum_sum_eigenvalues, where='mid',label='Skumulowana wyjaśniona wariancja')\n",
    "plt.ylabel('Wariancja',fontsize = 20)\n",
    "plt.xlabel('Indeks głównej składowej',fontsize = 20)\n",
    "plt.legend(loc='best',fontsize = 20)\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize=(40, 40))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_sum_eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla celów dalszej analizy biorę 5 komponentów, które łącznie wyjaśniają ponad 62% wariancji zbioru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "principalComponents = pca.fit_transform(data_std)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal_component_1', 'principal_component_2', 'principal_component_3','principal_component_4','principal_component_5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wizualizacje komponentów w 2 i 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.scatter(principalDf['principal_component_1'], principalDf['principal_component_2'],c='blue', s=70, alpha=0.005)\n",
    "plt.ylabel('Główna składowa nr 1',fontsize=20)\n",
    "plt.xlabel('Główna składowa nr 2',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.scatter(principalDf['principal_component_1'], principalDf['principal_component_3'],c='blue', s=70, alpha=0.005)\n",
    "plt.ylabel('Główna składowa nr 1',fontsize=20)\n",
    "plt.xlabel('Główna składowa nr 3',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "plt.scatter(principalDf['principal_component_2'], principalDf['principal_component_3'],c='blue', s=70, alpha=0.005)\n",
    "plt.ylabel('Główna składowa nr 2',fontsize=20)\n",
    "plt.xlabel('Główna składowa nr 3',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oceniajac wizualnie jedynie 1 i 2 komponent widać potencjalne 3 klastry, jednak po dodaniu do tego 3 komponentu wyłonić się może większa ich liczba. Dlatego będę musiał inną metodą ustalić optymalną liczbę klastrów. Poniżej wykres 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 20))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "ax.scatter3D(principalDf['principal_component_1'], principalDf['principal_component_2'], principalDf['principal_component_3'], color = \"blue\",alpha=0.003,s=80)\n",
    "plt.title(\"3D Principal components visualization\")\n",
    "ax.set_xlabel('principal_component_1')\n",
    "ax.set_ylabel('principal_component_2')\n",
    "ax.set_zlabel('principal_component_3')\n",
    "ax.set_xlim3d(np.percentile(principalDf['principal_component_1'],[1,99])[0],np.percentile(principalDf['principal_component_1'],[1,99])[1])\n",
    "ax.set_ylim3d(np.percentile(principalDf['principal_component_2'],[1,99])[0],np.percentile(principalDf['principal_component_2'],[1,99])[1])\n",
    "ax.set_zlim3d(np.percentile(principalDf['principal_component_3'],[1,99])[0],np.percentile(principalDf['principal_component_3'],[1,99])[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W następnym kroku przeprowadzam dekompozycję PCA 1 i 2, żeby wizualnie ocenić, które zmienne mocno do nich kontrybuują."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "x_new = pca.fit_transform(data_std)\n",
    "labels = list(df_stats.columns)\n",
    "def myplot(score,coeff,labels=labels):\n",
    "    xs = score[:,0]\n",
    "    ys = score[:,1]\n",
    "    n = coeff.shape[0]\n",
    "    scalex = 1.0/(xs.max() - xs.min())\n",
    "    scaley = 1.0/(ys.max() - ys.min())\n",
    "    plt.scatter(xs * scalex,ys * scaley,c='blue', s=70, alpha=0.005)\n",
    "    for i in range(n):\n",
    "        plt.arrow(0, 0, coeff[i,0], coeff[i,1],color = 'black',alpha = 1)\n",
    "        if labels is None:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, \"Var\"+str(i+1), color = 'black', ha = 'center', va = 'center')\n",
    "        else:\n",
    "            plt.text(coeff[i,0]* 1.15, coeff[i,1] * 1.15, labels[i], color = 'black', ha = 'center', va = 'center')\n",
    "    plt.xlim(-0.5,0.5)\n",
    "    plt.ylim(-0.5,0.5)\n",
    "    plt.xlabel(\"Główna składowa nr {}\".format(1),fontsize=20)\n",
    "    plt.ylabel(\"Główna składowa nr {}\".format(2),fontsize=20)\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "myplot(x_new[:,0:2],np.transpose(pca.components_[0:2, :]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = data_std\n",
    "\n",
    "model = PCA(n_components=5).fit(train_features)\n",
    "X_pc = model.transform(train_features)\n",
    "n_pcs= model.components_.shape[0]\n",
    "most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "initial_feature_names = list(df_stats.columns)\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "dic = {'Główna składowa nr {}'.format(i+1): most_important_names[i] for i in range(n_pcs)}\n",
    "df = pd.DataFrame(dic.items(),columns = ['Główne składowe','Najistotniejsze zmienne'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z dekompozycji PCA wynika, że najistotniejsze zmienne w zbiorze pod względem objaśniania wariancji to:\n",
    "* goldEarnedPerMinute - liczba pieniedzy zarobiona przez gracza na minutę, \n",
    "* percentPhysical - udział obrażeń fizycznych w całości obrażeń oraz \n",
    "* damageTakenPerMinute - liczba obrażeń otrzymanych przez gracza na minutę. Wszystkie te zmienne moim zdaniem są intuicyjnymi wskaźnikami z jakim graczem mamy do czynienia - dobrym/złym - zarabiającym dużo czy mało, grającym postacią korzystającą z many i punktów umiejętności czy zadającą dużo obrażeń fizycznych itp. \n",
    "\n",
    "<br>Dodatkowo można zaobserwować, że są grupy zmiennych, które zachowują się podobnie i wynikaja z siebie, z ciekawszych par:\n",
    "* deathsPerMinute <-> emptyItemSlots: im częściej ktoś umiera w grze, tym ma mniej pieniędzy, tym mniej może kupić, tym więcej ma pustych slotów na przedmioty w grze albo\n",
    "* wardsPlacedPerMinute <-> percentMagic: postacie, ktore maja w LoLu zadanie pilnowania \"wizji mapy\" odpowiadaja za umieszczanie totemow (przedmiotow, ktore zapewniaja widocznosc obszaru, ktory normalnie jest ukryty) na mapie zwykle sa postaciami poslugujacymi sie magia, stad wraz z rosnieciem udzialu magicznych obrazen, rosnie liczba stawianych totemow\n",
    "* experiencePerMinute <-> deathsPerMinute: duza liczba smierci nie sprzyja mozliwosci zdobywania doswiadczenia w grze :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasteryzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pierwszej kolejnosci chce poznac optymalna liczbe klastrow i zweryfikowac hipoteze, ze jest to 5 klastrow - bo tyle mamy predefiniowanych rol w LoLu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data = principalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    # Create a KMeans instance with k clusters: model\n",
    "    model = KMeans(n_clusters=k)\n",
    "    \n",
    "    # Fit model to samples\n",
    "    model.fit(kmeans_data)\n",
    "    \n",
    "    # Append the inertia to the list of inertias\n",
    "    inertias.append(model.inertia_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10, 10))\n",
    "plt.plot(ks, inertias, '-o', color='black')\n",
    "plt.xlabel('Liczba klastrów k',fontsize = 20)\n",
    "plt.ylabel('Inercja',fontsize = 20)\n",
    "plt.xticks(ks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(inertias)):\n",
    "    print(inertias[i-1]-inertias[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z metody \"lokciowej\" moim zdaniem nie wylania sie w oczywisty sposob optymalna liczba klastrow - potencjalnie mogloby to byc 4-6. Zeby byc dokladniejszym posluze sie metoda silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "parameter_grid = ParameterGrid({'n_clusters': parameters})\n",
    "best_score = -1\n",
    "kmeans_model = KMeans()\n",
    "silhouette_scores = []\n",
    "\n",
    "for p in parameter_grid:\n",
    "    kmeans_model.set_params(**p)    \n",
    "    kmeans_model.fit(kmeans_data)         \n",
    "    ss = silhouette_score(kmeans_data, kmeans_model.labels_, sample_size = 1000, random_state=112)   \n",
    "    silhouette_scores += [ss]      \n",
    "    print('Parameter:', p, 'Silhouette score:', ss)\n",
    "    if ss > best_score:\n",
    "        best_score = ss\n",
    "        best_grid = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 10))\n",
    "plt.bar(range(len(silhouette_scores)), list(silhouette_scores), align='center', color='black', width=0.5)\n",
    "plt.xticks(range(len(silhouette_scores)), list(parameters))\n",
    "# plt.title('Silhouette Score', fontweight='bold')\n",
    "plt.xlabel('Liczba klastrów k',fontsize=20)\n",
    "plt.ylabel('Współczynnik Silhouette',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wielokrotnie testowalem rozny root, ale zawsze wychodzi, ze najlepsza liczba klastrow to 4. Zatem w docelowej analizie posluze sie ta liczba jako optymalna liczba. Teraz sprawdze jak klasteryzacja z n=5 bedzie miala sie do rol definiowanych przez gre (zmienna teamPosition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "five_clusters = KMeans(n_clusters=5,random_state = 101)\n",
    "five_clusters.fit(kmeans_data)\n",
    "predict=five_clusters.predict(kmeans_data)\n",
    "centroids = five_clusters.cluster_centers_\n",
    "kmeans_data['label'] = pd.Series(predict, index=kmeans_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,20\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {0:'red', 1:'magenta', 2:'blue', 3:'yellow', 4:'cyan'}\n",
    "\n",
    "ax.scatter(kmeans_data['principal_component_1'], kmeans_data['principal_component_2'], c=kmeans_data['label'].map(colors),alpha = 0.05)\n",
    "scatter = ax.scatter(kmeans_data['principal_component_1'], kmeans_data['principal_component_2'], c=kmeans_data['label'].map(colors),alpha = 0.05)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'black',marker='X')\n",
    "ax.set_xlabel('Główna składowa 1',fontsize = 20)\n",
    "ax.set_ylabel('Główna składowa 2',fontsize = 20)\n",
    "markers = [plt.Line2D([0,0],[0,0],color=color, linewidth=20, marker='o', linestyle='') for color in colors.values()]\n",
    "plt.legend(markers, colors.keys(), numpoints=1,fontsize = 15,title = 'Segmenty', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,20\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {0:'red', 1:'magenta', 2:'blue', 3:'yellow', 4:'cyan'}\n",
    "\n",
    "ax.scatter(kmeans_data['principal_component_1'], kmeans_data['principal_component_3'], c=kmeans_data['label'].map(colors),alpha = 0.05)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'black',marker='X')\n",
    "ax.set_xlabel('Główna składowa numer 1')\n",
    "ax.set_ylabel('Główna składowa numer 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,20\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {0:'red', 1:'magenta', 2:'blue', 3:'yellow', 4:'cyan'}\n",
    "\n",
    "ax.scatter(kmeans_data['principal_component_2'], kmeans_data['principal_component_3'], c=kmeans_data['label'].map(colors),alpha = 0.05)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'black',marker='X')\n",
    "ax.set_xlabel('Główna składowa numer 2')\n",
    "ax.set_ylabel('Główna składowa numer 3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 20))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "ax.scatter3D(kmeans_data['principal_component_1'], kmeans_data['principal_component_2'], kmeans_data['principal_component_3'], color = kmeans_data['label'].map(colors),alpha=0.03,s=80)\n",
    "ax.scatter3D(centroids[:,0] , centroids[:,1] , centroids[:,2] , s = 150, color = 'black',marker='X',alpha = 1)\n",
    "plt.title(\"simple 3D scatter plot\")\n",
    "ax.set_xlabel('principal_component_1')\n",
    "ax.set_ylabel('principal_component_2')\n",
    "ax.set_zlabel('principal_component_3')\n",
    "ax.set_xlim3d(np.percentile(kmeans_data['principal_component_1'],[1,99])[0],np.percentile(kmeans_data['principal_component_1'],[1,99])[1])\n",
    "ax.set_ylim3d(np.percentile(kmeans_data['principal_component_2'],[1,99])[0],np.percentile(kmeans_data['principal_component_2'],[1,99])[1])\n",
    "ax.set_zlim3d(np.percentile(kmeans_data['principal_component_3'],[1,99])[0],np.percentile(kmeans_data['principal_component_3'],[1,99])[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po podziale na 5 sztucznie narzuconych klastrow chce sprawdzic jak maja sie one do rol z poczatkowego zbioru, czy sie pokrywaja w duzym stopniu. Dodatkowo chce poznac co charakteryzuje reprezentantow poszczegolnych segmentow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial = dane_filtered_columns\n",
    "data_initial['cluster'] = pd.Series(predict, index=data_initial.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_5_clusters = adjusted_mutual_info_score(data_initial['teamPosition'],data_initial['cluster'])\n",
    "ari_5_clusters = adjusted_rand_score(data_initial['teamPosition'],data_initial['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = data_initial.groupby('cluster').mean(1).reset_index()\n",
    "columns = x1.columns\n",
    "\n",
    "count=1\n",
    "plt.subplots(figsize=(20, 40))\n",
    "for i in range(0,len(columns)):\n",
    "    plt.subplot(9,4,count)\n",
    "    plt.bar(x1.index, x1.iloc[:, i], color=\"black\")\n",
    "    plt.ylabel(columns[i])\n",
    "    plt.title(columns[i])\n",
    "    count+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charakterystyki klastrow:\n",
    "\n",
    "  1 przeciętniak, w żadnej statystyce się nie wybija ani na plus ani na minus, jedynie zauważalnie częściej gra postaciami nastawionymi na obrażenia fizyczne niż na magiczne, pasuje to do opisu ról TOP/JUNGLE, ale równie dobrze, mogą być to po prostu BOTTOMy, tylko grające słabiej\n",
    " <br> 2 asystent, ma duży udzial w zabojstwach, choc tylko w formie asyst, bo nie zadaje za duzo obrazen, dba o wizje mapy poprzez umieszczanie i niszczenie wrogich totemow, ponadprzecietnie duzo obrazen zadaje postaciom, zabija wyjatkowo malo minionow - typowa rola UTILITY (czyli tzw. support)\n",
    " <br> 4 zwycięzcy, duzo zabijaja, malo gina, zadaja i przyjmuja duzo obrazen - sa w srodku akcji, zadaja w zdecydowanej wiekszosci obrazenia fizyczne i dominuja w niszczeniu fortyfikacji przeciwnika - po prostu dobrzy gracze, jeśli musiałbym przyporządkować do tego segmentu jakąś konkretną rolę to byłby to BOTTOM (czyli tzw. AD carry)\n",
    " <br> 3 niedoświadczeni, uczący się gracze, często kończą swoje gry szybko, bo przegrywają i się poddają, trochę częściej gra postaciami nastawionymi na obrażenia fizyczne niż magiczne\n",
    " <br> 0 magicy, obok klastra nr 3 jest to drugi najlepszy gracz w druzynie, zadaje duzo obrazen, udaje mu sie czesto zabijac przeciwnikow, gra prawie wylacznie magicznymi postaciami i takie obrazenia tez u niego przewazaja - typowe charakterystyki roli MIDDLE (czyli tzw. mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = data_initial[['cluster','teamPosition','teamId','championName']]\n",
    "counter[['cluster','teamPosition']].groupby('cluster').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liczebności klastrów są dosyć nierówne, najwięcej mamy przeciętniaków (co zdecydowanie ma sens, potwierdzałoby to też hipotezę o mixie 2-3 ról). Najmniej jest za to asystentów i graczy naprawdę dobrych - co również ma pewien sens. Gdy są wybierane role, nikt nie chce być supportem (przyjeło się myśleć, że ta rola jest nudna i niepotrzebna), a elitarnych graczy z definicji musi być niewielu :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(counter[['cluster','teamPosition','teamId']],index='teamPosition',columns='cluster',aggfunc='count',margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nałożenie klastrów na role pozwala potwierdzić pierwotne przypuszczenia odnośnie zależności segmentów od ról - tzn.:\n",
    "- klaster 1 mieszanka ról, z najmniejszym udziałem supportów, sytuacja podobna do klastra 3 - gracze przeciętni zdarzają się na każdej pozycji i jest to całkowicie naturalne\n",
    "- klaster 2 to stricte supporty\n",
    "- klaster 4 bez silniejszej przynależności do roli, dobry gracz odnajdzie się w każdej z ról (poza supportem), ale zgodnie z podejrzeniami jest tu najwięcej AD carry (BOTTOM)\n",
    "- klaster 3 jest bardzo zrównoważony pod względem ról - to po prostu są gracze słabi/początkujący, którzy niezależnie od roli radzą sobie kiepsko i muszą zbierać doświadczenie\n",
    "- klaster 0 przeważają gracze grający na midzie, ale zdażają się też junglerzy i topy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrócmy do optymalnej liczby klastrów - 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10982)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "four_clusters = KMeans(n_clusters=4,random_state=123)\n",
    "four_clusters.fit(kmeans_data)\n",
    "predict=four_clusters.predict(kmeans_data)\n",
    "centroids = four_clusters.cluster_centers_\n",
    "kmeans_data['label'] = pd.Series(predict, index=kmeans_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 20,20\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = {0:'red', 1:'magenta', 2:'blue', 3:'yellow'}\n",
    "\n",
    "ax.scatter(kmeans_data['principal_component_1'], kmeans_data['principal_component_2'], c=kmeans_data['label'].map(colors),alpha = 0.05)\n",
    "plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'black',marker='X')\n",
    "ax.set_xlabel('Główna składowa 1',fontsize = 20)\n",
    "ax.set_ylabel('Główna składowa 2',fontsize = 20)\n",
    "markers = [plt.Line2D([0,0],[0,0],color=color, linewidth=20, marker='o', linestyle='') for color in colors.values()]\n",
    "plt.legend(markers, colors.keys(), numpoints=1,fontsize = 15,title = 'Segmenty', loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20, 20))\n",
    "ax = plt.axes(projection =\"3d\")\n",
    "\n",
    "ax.scatter3D(kmeans_data['principal_component_1'], kmeans_data['principal_component_2'], kmeans_data['principal_component_3'], color = kmeans_data['label'].map(colors),alpha=0.03,s=80)\n",
    "ax.scatter3D(centroids[:,0] , centroids[:,1] , centroids[:,2] , s = 150, color = 'black',marker='X',alpha = 1)\n",
    "plt.title(\"simple 3D scatter plot\")\n",
    "ax.set_xlabel('principal_component_1')\n",
    "ax.set_ylabel('principal_component_2')\n",
    "ax.set_zlabel('principal_component_3')\n",
    "ax.set_xlim3d(np.percentile(kmeans_data['principal_component_1'],[1,99])[0],np.percentile(kmeans_data['principal_component_1'],[1,99])[1])\n",
    "ax.set_ylim3d(np.percentile(kmeans_data['principal_component_2'],[1,99])[0],np.percentile(kmeans_data['principal_component_2'],[1,99])[1])\n",
    "ax.set_zlim3d(np.percentile(kmeans_data['principal_component_3'],[1,99])[0],np.percentile(kmeans_data['principal_component_3'],[1,99])[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial = dane_filtered_columns\n",
    "data_initial['cluster'] = pd.Series(predict, index=data_initial.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ami_4_clusters = adjusted_mutual_info_score(data_initial['teamPosition'],data_initial['cluster'])\n",
    "ari_4_clusters = adjusted_rand_score(data_initial['teamPosition'],data_initial['cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('5 clusters')\n",
    "print('AMI: '+str(ami_5_clusters))\n",
    "print('ARI: '+str(ari_5_clusters))\n",
    "print('--------------------------')\n",
    "print('4 clusters')\n",
    "print('AMI: '+str(ami_4_clusters))\n",
    "print('ARI: '+str(ari_4_clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data_initial.groupby('cluster').mean(1).reset_index()\n",
    "columns = x1.columns\n",
    "x1 =x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x1 = data_initial.groupby('cluster').mean(1).reset_index()\n",
    "columns = x1.columns\n",
    "\n",
    "count=1\n",
    "plt.subplots(figsize=(20, 40))\n",
    "for i in range(0,len(columns)):\n",
    "    plt.subplot(9,4,count)\n",
    "    plt.bar(x1['cluster'], x1.iloc[:, i], color=\"black\")\n",
    "    plt.ylabel(columns[i])\n",
    "    plt.title(columns[i])\n",
    "    count+=1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = data_initial[['cluster','teamPosition','teamId','championName']]\n",
    "counter[['cluster','teamPosition']].groupby('cluster').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(counter[['cluster','teamPosition','teamId']],index='teamPosition',columns='cluster',aggfunc='count',margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charakterystyki klastrów w optymalnym wydaniu:\n",
    "\n",
    "1 bardzo duza liczebnosc, dobrzy gracze, zadajacy duze obrazenia, prawie wylacznie fizyczne, wysoki wspolczynnik zabojstw do smierci - analogicznie do poprzedniej klasteryzacji - to najprawdopodobniej mieszanka BOTTOM, JUNGLE i TOP\n",
    "<br>3 magicy\n",
    "<br>2 stricte supporty\n",
    "<br>0 przegrywajacy, niedoswiadczeni gracze z kazdej pozycji\n",
    "\n",
    "Zatem obnizenie klastrow do 4 spowodowalo znikniecie segmentu przecietniakow, klastry rzeczywiscie bardziej sie od siebie roznia pod wzgledem charakterystyk, ale niewiele dodaje to informacji o podziale miedzy role - ARI i AMI pozostaja na zblizonym poziomie i wciaz klastry slabo pokrywaja sie z ground truth w postaci pozycji opisanej zmienna <b>teamPosition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# klasyfikacja (regresja logistyczna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W zwiazku z tym, ze klastry nie pokrywaja mi sie w zadowalajacym stopniu z rolami poszczegolnych graczy, zdecydowalem, ze policze \"archetypy\" poszczegolnych rol i policze \"niestandardowosc\" rozgrywki w porownaniu z archetypami kazdej z rol, ktora powinien odgrywac gracz. W tym celu skorzystalem z 2 komponentow z PCA, na ich podstawie policzylem mediane dla kazdej z rol - bedzie to moj archetyp. Nastepnie na podstawie odleglosci euklidejskiej obliczylem jak niestandardowo ktos gral. Takie odleglosci bede nastepnie wpuszczam do modelu regresji logistycznej ze zmienna celu WIN - chce sprawdzic czy niestandardowosc rozgrywki pomoze mi przewidziec czy ktos wygral czy przegral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_initial = data_initial[['teamPosition','win']]\n",
    "coordinates = pd.merge(kmeans_data,data_initial,left_index=True,right_index=True).set_index('teamPosition')\n",
    "meta_calculation = pd.merge(kmeans_data,data_initial,left_index=True,right_index=True)\n",
    "meta_calculation = meta_calculation.groupby('teamPosition').agg({'principal_component_1': 'median', 'principal_component_2': 'median'})\n",
    "meta_calculation.columns = ['principal_component_1_meta','principal_component_2_meta']\n",
    "coordinates = pd.merge(coordinates,meta_calculation,left_index=True,right_index=True)\n",
    "coordinates['euclidean_distance'] = np.sqrt((coordinates['principal_component_1']-coordinates['principal_component_1_meta']).pow(2)+(coordinates['principal_component_2']-coordinates['principal_component_2_meta']).pow(2))\n",
    "coordinates = coordinates.reset_index()\n",
    "coordinates = coordinates[['win','teamPosition','euclidean_distance']]\n",
    "coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['teamPosition','win']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['teamPosition','win']).agg({'euclidean_distance':['mean','median']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('win').agg({'euclidean_distance':['mean','median']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zbior jest wysoce zbalansowany - to dobrze. Analizujac roznice w srednich i medianach miedzy zwycieskimi i przegranymi rozgrywkami mozna przypuszczac, ze niestandardowosc rozgrywki (nietrzymanie sie archetypu) zwieksza szanse zwyciestwa, co postaram sie zweryfikowac przy pomocy modelu regresji logistycznej. Zaskakujace jest jednak to, ze w roli, ktora najlatwiej rozpoznac (support) wartosci miary niestandardowosci sa niskie (gracze graja w zblizony sposob) i niewiele roznia sie srednie miedzy zwycieskimi rozgrywkami i przegranymi (niestandardowosc rozgrywki supportu nie powinna miec wplywu na ostateczny wynik meczu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['euclidean_distance']\n",
    "y=data['win']\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train = X_train.values.reshape(-1,1)\n",
    "y_train = y_train.values.reshape(-1,1)\n",
    "X_test = X_test.values.reshape(-1,1)\n",
    "y_test = y_test.values.reshape(-1,1)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienna jest istotna statystycznie i rzeczywiscie wraz ze wzrostem niestandardowosci szanse na zwyciestwo sie zwiekszaja, ale ogolna moc predykcyjna modelu jest bardzo mizerna. Sprobuje jeszcze zweryfikowac jak by to wygladalo dla kazdej roli oddzielnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "positions = ['BOTTOM','JUNGLE','MIDDLE','TOP','UTILITY']\n",
    "\n",
    "for i in range(0,len(positions)):\n",
    "    print('___________________________')\n",
    "    print(positions[i])\n",
    "    print('___________________________')\n",
    "    temporary = data[data.teamPosition.eq(positions[i])]\n",
    "    X=temporary['euclidean_distance']\n",
    "    y=temporary['win']\n",
    "    logit_model=sm.Logit(y,X)\n",
    "    result=logit_model.fit()\n",
    "    print(result.summary2())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    X_train = X_train.values.reshape(-1,1)\n",
    "    y_train = y_train.values.reshape(-1,1)\n",
    "    X_test = X_test.values.reshape(-1,1)\n",
    "    y_test = y_test.values.reshape(-1,1)\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla kazdej z rol poza UTILITY (support) zmienna mowiaca o niestandardowosci rozgrywki jest istotna statystycznie i jej wspolczynnik zawsze jest dodatni - co potwierdza tezę, że niestandardowe granie podwyższa szanse zwycięstwa drużyny gracza. Z zastrzeżeniem, że niestandardowa gra supporta nie daje drużynie zauważalnie większych szans zwycięstwa. Jednakże w żadnym przypadku jedynie informacja o odleglosci euklidesowej od archetypu nie wystarczy, żeby efektywnie prognozować zwycięstwo - accuracy = 0.53 to tak naprawde niewiele lepiej niz losowo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podsumowanie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dane zostaly wyczyszczone i przygotowane do wnioskowania i modelowania\n",
    "2. Potwierdzila sie hipoteza o wspoliniowosci zmiennych\n",
    "3. Zastosowano redukcje wielowymiarowosci przy uzyciu metody PCA, ktorej 5 komponentow pozwolilo wyjasnic ponad 62% wariancji\n",
    "4. Określono najistotniejsze zmienne w zbiorze, które najbardziej różnicują rozgrywki graczy\n",
    "5. Przeanalizowano zbior pod katem optymalnej liczby klastrow w segmentacji\n",
    "6. Nie potwierdzila sie hipoteza o 5 klastrach zaszytych w danych\n",
    "7. Przy zastosowaniu sztywnej wartosci n=5 segmentacja jedynie w przypadku 2 klastrow w oczywisty sposob wskazywala na konkretna role (support i mid)\n",
    "8. Przeanalizowano charakterystyki segmentow przy n=4, zastosowanie optymalnej liczby klastrow nie wplynelo na lepsze nalozenie sie klastrow na predefiniowane role (brak istotnych zmian w ARI i AMI).\n",
    "9. Opracowano miare niestandardowosci rozgrywki w danej roli\n",
    "10. Zbadano zaleznosc miedzy miara niestandardowosci i szansa na zwyciestwo\n",
    "11. Potwierdzila sie hipoteza, ze im bardziej niestandardowa/zaskakujaca gra, tym wieksze prawdopodobienstwo zwyciestwa, jednak tylko ta informacja to za malo, zeby prognozowac rezultaty meczy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Komentarze:\n",
    "\n",
    "Jako poglebienie moznaby stworzyc miare niestandardowosci gry calej druzyny (jakas suma odleglosci euklidesowych w obrebie druzyny x meczu y). <br>\n",
    "W analizie zostalo pominietych kilka waznych aspektow, takich jak postac, ktora gral dany gracz (jak ona odpowiadala roli, ktora powinien byl przyjac), jakie przedmioty kupowali gracze i gdzie tak faktycznie spedzali swoja rozgrywke (w meczach poczatkujacych czestym procederem jest zamienianie sie miedzy liniami, lepsi gracze proponuja, ze zamienia sie z kims, kto wpadl na lepszego od siebie rywala). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
